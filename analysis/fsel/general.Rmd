---
output: pdf_document
---
```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
rm(list = ls())
options(error=traceback)
library(clusterCrit)
set.seed(1)
```

``` {r echo=FALSE, warning=FALSE}
# Carga inicial de datos
setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results")
raw_data <- read.table("data.txt",sep="\t")
raw_meta <- read.table("meta.txt", sep="\t")
```

# Problema

Sea $P_{d}=\{p_{1}, ..., p_{M}\}$ el  perfil de consumo observado para un edificio en el día $d$, donde $M$ es el número de observaciones diarias. Luego, definimos $B=\{P_{1},...,P_{L}\}$ como el conjunto de perfiles de consumo de un edificio, con $L$ el número de días registrados. Sea $K=\{k_{1},..., k_{L}\}$ la lista de pertenencia de cada perfil de consumo de $B$ a un conjunto, donde $k_{i}\in \{1,..,G\}$ es el grupo al que pertenece la observación $P_{i}$ y $G$ es el número de grupos. 

Sea ahora $S=\{ s_{a},...,s_{z}\}$ una combinación de atributos, con $1 \leq a, z \leq M$. Dada una combinación de atributos o solución, definimos la funcion $clus(B, S) = \{c_{1}, ..., c_{L}\}$ que retorna el grupo al cual pertenece cada observación $P_{i} \in B$, donde ($c_{i} \in \{1,..,G\}$).

Luego, definimos la función $irand(K, clus(B,S)) = I$ (con $I \in \mathbb{R}$ e $I \in [0..1]$) que retorna la medida del **índice Rand** (comparación externa de clusters) para ambas agrupaciones, donde 1 es similitud total. 

Sea ahora *N* el número de edificios, entonces dada una solución $S$ de largo (cantidad de atributos que selecciona) igual a $||S||$, definimos la siguiente función de **fitness**:

$$ fitness(S) = 0.8 * ( \frac{1}{N}\sum^{N}_{p=1} irand(K_{p}, clus(B_{p},S)) )^{2} + 0.2 (1 - \frac{||S||}{M}) $$

Nótese que $K_{p}$ y $B_{p}$ corresponden a la agrupación y las observaciones del edificio $p$ respectivamente. Asimismo se añade un factor asociado a la cantidad de atributos seleccionados, pretendiendo así favorecer soluciones que escojan un menor número de atributos.

Ahora podemos definir el problema de encontrar el menor número de atributos con la menor pérdida de información, como encontrar la solución $S$ que maximiza el **fitness**.







# Resultados

Se cuenta con el consumo de electricidad medido con una periodicidad de 15 minutos durante un año para `r nrow(raw_meta)` edificios ($N=$`r nrow(raw_meta)`), es decir se cuenta con más de 2 millones de mediciones de consumo, y el objetivo consiste en seleccionar el conjunto mínimo de mediciones que permita realizar el análisis del consumo sin pérdida de información.

Para cada edificio de manera independiente se realiza la agrupación de cada perfil de consumo (desde las 0:00 hasta las 23:59) utilizando **k-means**. Se define agrupar dichos perfiles de consumo en 3 categorías (i.e. $G=3$). De esta forma se obtienen las listas de pertenencia $K_{p}$, con $p \in \{1,...,N\}$. 



## General: todos los edificios

Considerando el conjunto de todos los edificios y sus consumos diarios, se realiza la selección de atributos mínimos. Para ello realizar la búsqueda de la solución $S$ se utiliza un SSGA, el cual fue ejecutado 30 veces de manera independiente.

``` {r echo=FALSE, warning=FALSE}
# Obtenemos los datos
results_all <- list()
proc_times <- list()

setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results/all")
for(s in 1:30) {
  load(paste(s,"results-ssga.RData",sep="-"))
  results_all[[s]] <- results
  proc_times[[s]] <- list(beginning = time_beginning, end = time_end)
}

rm(results)
rm(time_beginning)
rm(time_end)
rm(s)
```


A continuación se muestra la gráfica de convergencia del algoritmo utilizado para la selección de atributos.

``` {r echo=FALSE, warning=FALSE}
# Seleccionamos una solución
solution <- 1
maxs <- results_all[[solution]]$max_gen
medians <- results_all[[solution]]$median_gen
sds <- results_all[[solution]]$sd_gen

# Graficamos la convergencia en el intervalo del fitness observado
plot(maxs,type="l", xlab="Generation", ylab="Fitness", lty=2, ylim=c(min(medians,maxs), max(medians,maxs)) ,main="Population Convergence", lwd=1.5, log="y")
lines(medians, type="l", lty=1)
legend("bottomright", legend=c("Max","Median"), lty=c(2,1), bty="n", horiz = TRUE)

# Graficamos la convergencia en el intervalo posible del fitness [0..1]
#plot(maxs,type="l", xlab="Generation", ylab="Fitness", lty=2, ylim=c(0,1) ,main="Population Convergence", lwd=1.5)
#lines(medians, type="l", lty=1)
#legend("bottomright", legend=c("Max","Median"), lty=c(2,1), bty="n", horiz = TRUE)

```


Los siguientes gráficos muestran el comportamiento del algoritmo en cuanto a la solución generada en términos del fitness y el número de atributos.

``` {r echo=FALSE, warning=FALSE}
best_fitness <- sapply(1:length(results_all), function(s) { results_all[[s]]$best_fitness })
best_features_size <- sapply(1:length(results_all), function(s) { results_all[[s]]$best_features_size })

# Revisamos la desviación de las soluciones en términos de número de variables y fitness
par(mfrow=c(1,2))
boxplot(best_features_size, ylab="# Features", ylim=c(1,96))
boxplot(best_fitness, ylab="Fitness", ylim=c(0,1))

# Obtenemos la media y desviación estándar
best_features_size_sd <- sd(best_features_size)
best_features_size_mean <- mean(best_features_size)
best_fitness_sd <- sd(best_fitness)
best_fitness_mean <- mean(best_fitness)
```

La siguiente tabla muestra la media y desviación estándar de las soluciones.

|         | SDev    | Mean    |
| :------ | ------: | ------: |
| Número de atributos | `r best_features_size_sd` | `r best_features_size_mean` |
| Fitness | `r best_fitness_sd` | `r best_fitness_mean` |


A continuación se muestra la relación entre el **fitness** y la cantidad de atributos seleccionados.

``` {r echo=FALSE, warning=FALSE}
# Graficamos la relación entre el número de variables y el fitness
par(mfrow=c(1,1))
plot(best_features_size, best_fitness, xlab="# Features", ylab="Fitness", main="Solutions", ylim=c(0.85,0.95))
```

Considerando las soluciones generadas, se busca obtener la lista de atributos más representativos. Para ello se presenta el siguiente histograma de frecuencia de aparición de cada atributo en las soluciones. Un mayor frecuencia se relaciona con la importancia relativa del atributo.

``` {r echo=FALSE, warning=FALSE}
# Convertimos la selección de atributos (de la mejor solución para cada ejecución) en una matriz
solutions_matrix <- t( sapply(1:length(results_all), function(s){ results_all[[s]]$best*1 }) )

# Obtenemos la hora a la que corresponde cada medida
list_hours <- colnames(raw_data)[!colnames(raw_data) %in% c("file_name","consumption_date")]
# Quitamos la X al comienzo del nombre de cada columna
list_hours <- sapply(list_hours, function(s) { substr(s, 2, nchar(s))})
freq_solution <- colSums(solutions_matrix)
# generamos un mapa de calor
col_palette <- rev(gray.colors(max(freq_solution)-min(freq_solution)+1))
#col_palette <- rev(heat.colors(max(freq_solution)-min(freq_solution)+1))
col_freqs <- sapply( (freq_solution - min(freq_solution) + 1), function(s) { col_palette[s] } )
barplot(freq_solution, names.arg = list_hours, col = col_freqs, xlab="Hour", ylab="Frequency", main="Attribute Selection Frequency")
```



## Edificios similares: Centros de salud

Considerando que el conjunto de edificios es heterogéneo, seleccionamos un subconjunto de ellos que presentaran características similares. Particularmente se seleccionaron los 5 "centros de salud" presentes en el conjunto. 

La idea es validar si es posible deducir a partir de una solución general, una solución particular para el problema planteado. En otras palabras, se pretende saber si existe alguna relación entre los comportamientos de los centros de salud. Para ello se ejecutará el proceso de búsqueda de la solución $S$, primero para el conjunto de los centros de salud y luego para uno de ellos en particular: **Centro de Salud Arroyo de la Miel**. A continuación compararemos los resultados obtenidos.

``` {r echo=FALSE, warning=FALSE}
# Obtenemos los datos del grupo
results_group <- list()
proc_times_group <- list()

setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results/cent-salud")
for(s in 1:30) {
  load(paste(s,"results-ssga.RData",sep="-"))
  results_group[[s]] <- results
  proc_times_group[[s]] <- list(beginning = time_beginning, end = time_end)
}

rm(results)
rm(time_beginning)
rm(time_end)
rm(s)
```

``` {r echo=FALSE, warning=FALSE}
# Obtenemos los datos de uno en particular
results_16 <- list()
proc_times_16 <- list()

setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results/16")
for(s in 1:30) {
  load(paste(s,"results-ssga.RData",sep="-"))
  results_16[[s]] <- results
  proc_times_16[[s]] <- list(beginning = time_beginning, end = time_end)
}

rm(results)
rm(time_beginning)
rm(time_end)
rm(s)
```

A continuación se muestra el comportamiento del algoritmo en cuanto a la solución generada en términos del fitness y en paralelo al número de atributos.

``` {r echo=FALSE, warning=FALSE}
# grupo
best_fitness_group <- sapply(1:length(results_group), function(s) { results_group[[s]]$best_fitness })
best_features_size_group <- sapply(1:length(results_group), function(s) { results_group[[s]]$best_features_size })

# uno
best_fitness_16 <- sapply(1:length(results_16), function(s) { results_16[[s]]$best_fitness })
best_features_size_16 <- sapply(1:length(results_16), function(s) { results_16[[s]]$best_features_size })

# Revisamos la desviación de las soluciones en términos de número de variables y fitness
par(mfrow=c(1,2))
boxplot(best_features_size_group, ylab="# Features", xlab="Grupo", ylim=c(1,96))
boxplot(best_features_size_16, ylab="# Features", xlab="Centro", ylim=c(1,96))

boxplot(best_fitness_group, ylab="Fitness", xlab="Grupo", ylim=c(0,1))
boxplot(best_fitness_16, ylab="Fitness", xlab="Centro", ylim=c(0,1))

# Obtenemos la media y desviación estándar
best_features_size_sd_group <- sd(best_features_size_group)
best_features_size_mean_group <- mean(best_features_size_group)
best_fitness_sd_group <- sd(best_fitness_group)
best_fitness_mean_group <- mean(best_fitness_group)

best_features_size_sd_16 <- sd(best_features_size_16)
best_features_size_mean_16 <- mean(best_features_size_16)
best_fitness_sd_16 <- sd(best_fitness_16)
best_fitness_mean_16 <- mean(best_fitness_16)
```

La siguiente tabla muestra la media y desviación estándar de las soluciones.

|         | SDev    | Mean    | 
| :------ | ------: | ------: | 
|         |     *Centros de Salud*  ||
| Número de atributos | `r best_features_size_sd_group` | `r best_features_size_mean_group` |
| Fitness | `r best_fitness_sd_group` | `r best_fitness_mean_group` | 
|         |     *Centro de Salud Arroyo de la Miel* ||
| Número de atributos | `r best_features_size_sd_16` | `r best_features_size_mean_16` |
| Fitness | `r best_fitness_sd_16` | `r best_fitness_mean_16` |

``` {r echo=FALSE, warning=FALSE}
# Convertimos la selección de atributos (de la mejor solución para cada ejecución) en una matriz
solutions_matrix_group <- t( sapply(1:length(results_group), function(s){ results_group[[s]]$best*1 }) )
freq_solution_group <- colSums(solutions_matrix_group)
# generamos un mapa de calor
col_palette_group <- rev(gray.colors(max(freq_solution_group)-min(freq_solution_group)+1))
col_freqs_group <- sapply( (freq_solution_group - min(freq_solution_group) + 1), function(s) { col_palette_group[s] } )

# uno
solutions_matrix_16 <- t( sapply(1:length(results_16), function(s){ results_16[[s]]$best*1 }) )
freq_solution_16 <- colSums(solutions_matrix_16)
# generamos un mapa de calor
col_palette_16 <- rev(gray.colors(max(freq_solution_16)-min(freq_solution_16)+1))
col_freqs_16 <- sapply( (freq_solution_16 - min(freq_solution_16) + 1), function(s) { col_palette_16[s] } )

list_hours <- colnames(raw_data)[-c(1,2)]
list_hours <- lapply(list_hours, function(s) { substr(s,2, nchar(s)) } )

par(mfrow=c(1,2))
barplot(freq_solution_group, names.arg = list_hours, col = col_freqs_group, xlab="Hour", ylab="Frequency", main="Centros de Salud")
barplot(freq_solution_16, names.arg = list_hours, col = col_freqs_16, xlab="Hour", ylab="Frequency", main="Arroyo de la Miel")
```


A continuación se muestran los perfiles de consumo representativos (centros de k-means) para las tres agrupaciones del edificio "Centro de Salud Arroyo de la Miel".

``` {r echo=FALSE, warning=FALSE}
select <- 16
num_clusters <- 3
raw_data_16 <- raw_data[which(raw_data$file_name == raw_meta$file_name[select]),]
raw_meta_16 <- raw_meta[select,]

matrix <- raw_data_16[,!colnames(raw_data_16) %in% c("file_name","consumption_date")]
set.seed(1)
kc <- kmeans(matrix, num_clusters, 30, 10)
par(mfrow=c(1,3))
plot(kc$centers[1,], type="l", ylim=c(min(kc$centers),max(kc$centers)), ylab="Consumption", xlab="Time", xaxt="n")
axis(1, at=1:96, labels=list_hours)
plot(kc$centers[2,], type="l", ylim=c(min(kc$centers),max(kc$centers)), ylab="Consumption", xlab="Time", xaxt="n")
axis(1, at=1:96, labels=list_hours)
plot(kc$centers[3,], type="l", ylim=c(min(kc$centers),max(kc$centers)), ylab="Consumption", xlab="Time", xaxt="n")
axis(1, at=1:96, labels=list_hours)
```




# Competidores

## General

Para revisar el desempeño del método propuesto realizamos la búsqueda aleatoria de soluciones (repetimos el proceso 30 veces).

``` {r echo=FALSE, warning=FALSE}
# Obtenemos los datos
proc_times_rand <- list()

setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results/all")

load("1-results-rand.RData")
fit_all_rand <- fitness_offspring
sol_all_rand <- offspring
proc_times_rand <- list(beginning = time_beginning, end = time_end)


rm(fitness_offspring)
rm(offspring)
rm(time_beginning)
rm(time_end)
```

Primero revisamos el comportamiento de las soluciones en cuanto a la cantidad de atributos seleccionados y a su fitness.

``` {r echo=FALSE, warning=FALSE}
len_all_rand <- sapply(1:nrow(sol_all_rand), function(s) { sum(sol_all_rand[s,]*1) })

# Revisamos la desviación de las soluciones en términos de número de variables y fitness
par(mfrow=c(1,2))
boxplot(len_all_rand, ylab="# Features", ylim=c(1,96))
boxplot(fit_all_rand, ylab="Fitness", ylim=c(0,1))

# Obtenemos la media y desviación estándar
rand_best_features_size_sd <- sd(len_all_rand)
rand_best_features_size_mean <- mean(len_all_rand)
rand_best_fitness_sd <- sd(fit_all_rand)
rand_best_fitness_mean <- mean(fit_all_rand)
```

La siguiente tabla muestra la media y desviación estándar de las soluciones.

|         | SDev    | Mean    |
| :------ | ------: | ------: |
| Número de atributos | `r rand_best_features_size_sd` | `r rand_best_features_size_mean` |
| Fitness | `r rand_best_fitness_sd` | `r rand_best_fitness_mean` |


``` {r echo=FALSE, warning=FALSE}

fitness <- matrix(c(best_fitness,fit_all_rand), nrow=30, dimnames=list(1:30,c("SSGA","Rand")))
friedman_t <- friedman.test(fitness)
```

El test de Friedman para la comparación del SSGA vs la búsqueda aleatoria entrega un **p-value** igual a $`r friedman_t$p.value`$. Por lo tanto existe una diferencia significativa entre ambos métodos.


## Individual

Considerando un edificio en particular (el mismo utilizado anteriormente), ejecutamos la búsqueda aleatoria del subconjunto de atributos (30 veces de manera independiente), y además realizamos la selección del subconjunto utilizando dos métodos de filtrado: **Ganancia de información** (IG) y **CFS** (correlación y entropía). Nótese que estas últimas son ejecutadas una vez y sus valores son replicados 30 veces para efectos de comparación.

``` {r echo=FALSE, warning=FALSE}
# Obtenemos los datos
results_rand_16 <- list()
results_cfs_16 <- list()
results_ig_16 <- list()

setwd("/home/andu/Documentos/uma/PHD/papers/vatia/results/16")
for(s in 1:30) {
  # Random
  load(paste(s,"results-rand.RData",sep="-"))
  results_rand_16[[s]] <- results
}
# Filter
load(paste(1,"results-filters.RData",sep="-"))
results_cfs_16[[1]] <- list( fitness= results$cfs_fitness, best=results$cfs_subset )
results_ig_16[[1]] <- list( fitness= results$ig_fitness, best=results$ig_subset )

for(s in 2:30) {
  results_cfs_16[[s]] <- results_cfs_16[[1]]
  results_ig_16[[s]] <- results_ig_16[[1]]
}

rm(results)
rm(time_beginning)
rm(time_end)
rm(s)
rm(time_beg_ig)
rm(time_end_ig)
rm(time_beg_cfs)
rm(time_end_cfs)

fitness_rand_16 <- sapply(1:length(results_rand_16), function(s) { results_rand_16[[s]]$fitness })
fitness_ig_16 <- sapply(1:length(results_ig_16), function(s) { results_ig_16[[s]]$fitness })
fitness_cfs_16 <- sapply(1:length(results_cfs_16), function(s) { results_cfs_16[[s]]$fitness })
size_rand_16 <- sapply(1:length(results_rand_16), function(s) { sum(results_rand_16[[s]]$individual*1) })
size_ig_16 <- sapply(1:length(results_ig_16), function(s) { length(results_ig_16[[s]]$best) })
size_cfs_16 <- sapply(1:length(results_cfs_16), function(s) { length(results_cfs_16[[s]]$best) })


fitness_16 <- matrix(c(best_fitness_16, fitness_rand_16, fitness_cfs_16, fitness_ig_16), nrow=30, dimnames=list(1:30,c("SSGA","Rand", "CFS", "IG")))
friedman_t_16 <- friedman.test(fitness_16)
```

A continuación se muestran las medidas estadísticas para las diferentes soluciones.

|    | Mín | Máx | Media | Mediana | Sdev |
| ------ | :------ | :------ | :------ | :------ | :------ |
| SSGA | `r min(best_fitness_16)` | `r max(best_fitness_16)` | `r mean(best_fitness_16)` | `r median(best_fitness_16)` | `r sd(best_fitness_16)` |
| Random | `r min(fitness_rand_16)` | `r max(fitness_rand_16)` | `r mean(fitness_rand_16)` | `r median(fitness_rand_16)` | `r sd(fitness_rand_16)` |
| IG | `r min(fitness_ig_16)` | `r max(fitness_ig_16)` | `r mean(fitness_ig_16)` | `r median(fitness_ig_16)` | `r sd(fitness_ig_16)` |
| CFS | `r min(fitness_cfs_16)` | `r max(fitness_cfs_16)` | `r mean(fitness_cfs_16)` | `r median(fitness_cfs_16)` | `r sd(fitness_cfs_16)` |


La ejecución del test de Friedman arroja un **p-value** igual a $`r friedman_t_16$p.value`$, por lo tanto podemos señalar que existe una diferencia significativa entre los cuatro métodos. Luego, concluimos que el método SSGA presenta soluciones mejores en términos de fitness.
