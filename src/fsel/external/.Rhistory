sel_measures <- c("Connectivity", "Dunn", "Silhouette")
ivs <- iv
rm(iv)
os <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
rm(os)
oss
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
num_clusters
length(list_matrix_con)
get_clusters <- function( l_matrix, num_clusters ) {
temp_clusters <- lapply(1:length(l_matrix), function(i) {
kc <- kmeans(l_matrix[[i]], num_clusters[[i]], 30, 10)
as.integer(kc$cluster)
})
return(temp_clusters)
}
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
ground_clusters
clusters
max_eval <- 50
results <- ga_cluster_similarity(num_genes, pop_size, prob_mutation, prob_crossover, max_eval, list_matrix_con, ground_clusters, num_clusters)
results$best
results$median_gen
results$best_fitness
select <- 16
raw_data_t <- raw_data[which(raw_data$file_name %in% raw_metadata$file_name[select]),]
raw_metadata_t <- raw_metadata[select,]
list_matrix_con <- data_2_lmat(raw_data_t,raw_metadata_t)
num_genes <- ncol(list_matrix_con[[1]])
# Tamaño de la población
pop_size <- 10
# Probabilidad de mutación
prob_mutation <- 1 / num_genes
# Probabilidad de crossover
prob_crossover <- 0.8
n_clust <- c(2:10)
ivs <- lapply(list_matrix_con, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
num_clusters
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
ground_clusters
gc <- ground_clusters
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
ground_clusters[[1]]-gc[[1]]
rm(list = ls())
optimal_clus <- function(list_ch) {
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
rm(list = ls())
library(clValid)
library(clusterCrit)
library(FSelector)
set.seed(1)
optimal_clus <- function(list_ch) {
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
optimal_clus <- function(list_ch) {
set.seed(1)
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
meta <- read.table("meta.txt",sep="\t")
data <- read.table("data.txt",sep="\t")
s <- 1
r_data <- data[which(data$file_name == meta$file_name[s]),]
r_data
r_metadata <- meta[s,]
r_metadata
unique(r_data$file_name)
r_matrix <- r_data[,!colnames(data) %in% c("file_name","consumption_date")]
optimal_clus <- function(lt) {
set.seed(1)
n_clust <- c(2:10)
iv <- clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
os <- optimalScores(iv, measures = sel_measures)
num_clusters <- as.numeric(as.character(val_mode(os$Clusters)))
return(num_clusters)
}
raw_data <- r_data
raw_metadata <- r_metadata
matrix <- r_matrix
selection <- s
raw_metadata$file_name[1]
raw_metadata$file_name
ground_clusters <- lapply(1:nrow(raw_metadata), function(s) {
temp <- matrix[which(raw_data$file_name == raw_metadata$file_name[s]),]
num_clusters <- optimal_clus(temp)
kc <- kmeans(temp, num_clusters, 30, 10)
df <- data.frame(temp,as.integer(kc$cluster))
colnames(df) <- c(colnames(matrix),"cluster")
df
})
val_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
ground_clusters <- lapply(1:nrow(raw_metadata), function(s) {
temp <- matrix[which(raw_data$file_name == raw_metadata$file_name[s]),]
num_clusters <- optimal_clus(temp)
kc <- kmeans(temp, num_clusters, 30, 10)
df <- data.frame(temp,as.integer(kc$cluster))
colnames(df) <- c(colnames(matrix),"cluster")
df
})
ground_clusters
cluster_matrix <- do.call("rbind", ground_clusters)
cluster_matrix
time_beg_cfs <- Sys.time()
cfs_subset <- cfs( cluster~., cluster_matrix)
time_end_cfs <- Sys.time()
cfs_subset
matrix
num_clusters <- optimal_clus(matrix)
num_clusters
kc <- kmeans(matrix, num_clusters, 30, 10)
kc$cluster
ground_clusters <- data.frame(matrix,as.integer(kc$cluster))
colnames(ground_clusters) <- c(colnames(matrix),"cluster")
ground_clusters
cfs_subset <- cfs( cluster~., cluster_matrix)
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% cfs_subset) ])
plot(kc$centers[1,])
plot(kc$centers[2,])
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% cfs_subset) ])
kc_cfs <- kmeans(new_matrix, num_clusters, 30, 10)
cfs_clusters <- as.integer(kc_cfs$cluster)
cfs_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], cfs_clusters, "ra")
cfs_cluster_fitness
cfs_cluster_fitness_norm <- (sum( as.numeric(cfs_cluster_fitness) ) / length(cfs_cluster_fitness))**2
cfs_length_fitness <- 1 - length(cfs_subset)/ncol(matrix)
cfs_fitness <- 0.8*cfs_cluster_fitness_norm + 0.2*cfs_length_fitness
time_beg_ig <- Sys.time()
ig_weights <- symmetrical.uncertainty(cluster~., cluster_matrix)
ig_subset <- cutoff.biggest.diff(ig_weights)
time_end_ig <- Sys.time()
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% ig_subset) ])
kc_ig <- kmeans(new_matrix, num_clusters, 30, 10)
ig_clusters <- as.integer(kc_ig$cluster)
ig_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], ig_clusters, "ra")
ig_cluster_fitness_norm <- (sum( as.numeric(ig_cluster_fitness) ) / length(ig_cluster_fitness))**2
ig_length_fitness <- 1 - length(ig_subset)/ncol(matrix)
ig_fitness <- 0.8*ig_cluster_fitness_norm + 0.2*ig_length_fitness
results <- list( cfs_fitness= cfs_fitness, cfs_subset= cfs_subset, ig_fitness = ig_fitness, ig_subset = ig_subset)
results
rm(list = ls())
val_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
optimal_clus <- function(lt) {
set.seed(1)
n_clust <- c(2:10)
iv <- clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal")
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
os <- optimalScores(iv, measures = sel_measures)
num_clusters <- as.numeric(as.character(val_mode(os$Clusters)))
return(num_clusters)
}
meta <- read.table("meta.txt",sep="\t")
data <- read.table("data.txt",sep="\t")
f_selection <- function(matrix, selection) {
#num_clusters <- 3
num_clusters <- optimal_clus(matrix)
set.seed(1)
# Consideramos que la "verdad" se obtiene al realizar la agrupación utilizando todas las variables
kc <- kmeans(matrix, num_clusters, 30, 10)
ground_clusters <- data.frame(matrix,as.integer(kc$cluster))
colnames(ground_clusters) <- c(colnames(matrix),"cluster")
# usando cfs obtenemos los atributos más relevantes
time_beg_cfs <- Sys.time()
cfs_subset <- cfs( cluster~., cluster_matrix)
time_end_cfs <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% cfs_subset) ])
kc_cfs <- kmeans(new_matrix, num_clusters, 30, 10)
cfs_clusters <- as.integer(kc_cfs$cluster)
cfs_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], cfs_clusters, "ra")
cfs_cluster_fitness_norm <- (sum( as.numeric(cfs_cluster_fitness) ) / length(cfs_cluster_fitness))**2
cfs_length_fitness <- 1 - length(cfs_subset)/ncol(matrix)
cfs_fitness <- 0.8*cfs_cluster_fitness_norm + 0.2*cfs_length_fitness
# usando information gain obtenemos los atributos más relevantes
time_beg_ig <- Sys.time()
ig_weights <- symmetrical.uncertainty(cluster~., cluster_matrix)
ig_subset <- cutoff.biggest.diff(ig_weights)
time_end_ig <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% ig_subset) ])
kc_ig <- kmeans(new_matrix, num_clusters, 30, 10)
ig_clusters <- as.integer(kc_ig$cluster)
ig_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], ig_clusters, "ra")
ig_cluster_fitness_norm <- (sum( as.numeric(ig_cluster_fitness) ) / length(ig_cluster_fitness))**2
ig_length_fitness <- 1 - length(ig_subset)/ncol(matrix)
ig_fitness <- 0.8*ig_cluster_fitness_norm + 0.2*ig_length_fitness
results <- list( cfs_fitness= cfs_fitness, cfs_subset= cfs_subset, ig_fitness = ig_fitness, ig_subset = ig_subset)
# Guardamos los resultados
dir.create(as.character(selection))
file <- paste(1,"results-filters.RData", sep="-")
file <- paste(selection,"/",file, sep="")
save(results, time_beg_ig, time_end_ig, time_beg_cfs, time_end_cfs, file=file)
}
s <- 1
r_data <- data[which(data$file_name == meta$file_name[s]),]
r_metadata <- meta[s,]
r_matrix <- r_data[,!colnames(data) %in% c("file_name","consumption_date")]
f_selection(r_matrix, s)
f_selection <- function(matrix, selection) {
#num_clusters <- 3
num_clusters <- optimal_clus(matrix)
set.seed(1)
# Consideramos que la "verdad" se obtiene al realizar la agrupación utilizando todas las variables
kc <- kmeans(matrix, num_clusters, 30, 10)
cluster_matrix <- data.frame(matrix,as.integer(kc$cluster))
colnames(cluster_matrix) <- c(colnames(matrix),"cluster")
# usando cfs obtenemos los atributos más relevantes
time_beg_cfs <- Sys.time()
cfs_subset <- cfs( cluster~., cluster_matrix)
time_end_cfs <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% cfs_subset) ])
kc_cfs <- kmeans(new_matrix, num_clusters, 30, 10)
cfs_clusters <- as.integer(kc_cfs$cluster)
cfs_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], cfs_clusters, "ra")
cfs_cluster_fitness_norm <- (sum( as.numeric(cfs_cluster_fitness) ) / length(cfs_cluster_fitness))**2
cfs_length_fitness <- 1 - length(cfs_subset)/ncol(matrix)
cfs_fitness <- 0.8*cfs_cluster_fitness_norm + 0.2*cfs_length_fitness
# usando information gain obtenemos los atributos más relevantes
time_beg_ig <- Sys.time()
ig_weights <- symmetrical.uncertainty(cluster~., cluster_matrix)
ig_subset <- cutoff.biggest.diff(ig_weights)
time_end_ig <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% ig_subset) ])
kc_ig <- kmeans(new_matrix, num_clusters, 30, 10)
ig_clusters <- as.integer(kc_ig$cluster)
ig_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], ig_clusters, "ra")
ig_cluster_fitness_norm <- (sum( as.numeric(ig_cluster_fitness) ) / length(ig_cluster_fitness))**2
ig_length_fitness <- 1 - length(ig_subset)/ncol(matrix)
ig_fitness <- 0.8*ig_cluster_fitness_norm + 0.2*ig_length_fitness
results <- list( cfs_fitness= cfs_fitness, cfs_subset= cfs_subset, ig_fitness = ig_fitness, ig_subset = ig_subset)
# Guardamos los resultados
dir.create(as.character(selection))
file <- paste(1,"results-filters.RData", sep="-")
file <- paste(selection,"/",file, sep="")
save(results, time_beg_ig, time_end_ig, time_beg_cfs, time_end_cfs, file=file)
}
f_selection(r_matrix, s)
f_selection <- function(matrix, selection) {
#num_clusters <- 3
num_clusters <- optimal_clus(matrix)
set.seed(1)
# Consideramos que la "verdad" se obtiene al realizar la agrupación utilizando todas las variables
kc <- kmeans(matrix, num_clusters, 30, 10)
ground_clusters <- data.frame(matrix,as.integer(kc$cluster))
colnames(ground_clusters) <- c(colnames(matrix),"cluster")
# usando cfs obtenemos los atributos más relevantes
time_beg_cfs <- Sys.time()
cfs_subset <- cfs( cluster~., ground_clusters)
time_end_cfs <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% cfs_subset) ])
kc_cfs <- kmeans(new_matrix, num_clusters, 30, 10)
cfs_clusters <- as.integer(kc_cfs$cluster)
cfs_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], cfs_clusters, "ra")
cfs_cluster_fitness_norm <- (sum( as.numeric(cfs_cluster_fitness) ) / length(cfs_cluster_fitness))**2
cfs_length_fitness <- 1 - length(cfs_subset)/ncol(matrix)
cfs_fitness <- 0.8*cfs_cluster_fitness_norm + 0.2*cfs_length_fitness
# usando information gain obtenemos los atributos más relevantes
time_beg_ig <- Sys.time()
ig_weights <- symmetrical.uncertainty(cluster~., ground_clusters)
ig_subset <- cutoff.biggest.diff(ig_weights)
time_end_ig <- Sys.time()
# seleccionamos los atributos más relevantes
new_matrix <- as.matrix(matrix[ ,which(colnames(matrix) %in% ig_subset) ])
kc_ig <- kmeans(new_matrix, num_clusters, 30, 10)
ig_clusters <- as.integer(kc_ig$cluster)
ig_cluster_fitness <- extCriteria(ground_clusters[,"cluster"], ig_clusters, "ra")
ig_cluster_fitness_norm <- (sum( as.numeric(ig_cluster_fitness) ) / length(ig_cluster_fitness))**2
ig_length_fitness <- 1 - length(ig_subset)/ncol(matrix)
ig_fitness <- 0.8*ig_cluster_fitness_norm + 0.2*ig_length_fitness
results <- list( cfs_fitness= cfs_fitness, cfs_subset= cfs_subset, ig_fitness = ig_fitness, ig_subset = ig_subset)
# Guardamos los resultados
dir.create(as.character(selection))
file <- paste(1,"results-filters.RData", sep="-")
file <- paste(selection,"/",file, sep="")
save(results, time_beg_ig, time_end_ig, time_beg_cfs, time_end_cfs, file=file)
}
f_selection(r_matrix, s)
results
select <- 1:64
fs <- lapply(select, function(s) {
r_data <- data[which(data$file_name == meta$file_name[s]),]
r_metadata <- meta[s,]
r_matrix <- r_data[,!colnames(data) %in% c("file_name","consumption_date")]
f_selection(r_matrix, s)
})
?kmeans
s <- 9
r_data <- data[which(data$file_name == meta$file_name[s]),]
r_metadata <- meta[s,]
r_matrix <- r_data[,!colnames(data) %in% c("file_name","consumption_date")]
nrow(r_matrix)
f_selection(r_matrix, s)
select <- 10:64
fs <- lapply(select, function(s) {
r_data <- data[which(data$file_name == meta$file_name[s]),]
r_metadata <- meta[s,]
r_matrix <- r_data[,!colnames(data) %in% c("file_name","consumption_date")]
f_selection(r_matrix, s)
})
rm(list=ls())
library(clValid)
source("ssga.r")
val_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
optimal_clus <- function(list_ch) {
set.seed(1)
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal", maxitems=1000)
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
metadata <- read.table("meta.txt",sep="\t")
data <- read.table("data.txt",sep="\t")
raw_data <- data
raw_metadata <- metadata
select <- 1
seed <- 1
raw_data_t <- raw_data[which(raw_data$file_name %in% raw_metadata$file_name[select]),]
raw_metadata_t <- raw_metadata[select,]
list_matrix_con <- data_2_lmat(raw_data_t,raw_metadata_t)
num_clusters <- optimal_clus(list_matrix_con)
num_clusters
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
ground_clusters
num_genes <- ncol(list_matrix_con[[1]])
time_beginning <- Sys.time()
set.seed(seed)
pop <- init_pop(1,num_genes)
time_end <- Sys.time()
fitness <- evaluate_individual(pop[1,], list_matrix_con, ground_clusters, num_clusters)
fitness
pop
pop*1
sum(pop*1)
random_search <- function(raw_data, raw_metadata, select, seed) {
raw_data_t <- raw_data[which(raw_data$file_name %in% raw_metadata$file_name[select]),]
raw_metadata_t <- raw_metadata[select,]
# Convertimos los datos al formato de entrada del algoritmo
list_matrix_con <- data_2_lmat(raw_data_t,raw_metadata_t)
# Número de clusters
num_clusters <- optimal_clus(list_matrix_con)
# obtenemos la "verdad"
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
# El número de genes corresponde a la cantidad de observaciones de un día
num_genes <- ncol(list_matrix_con[[1]])
# Generamos una serie de individuos aleatorios
time_beginning <- Sys.time()
set.seed(seed)
pop <- init_pop(1,num_genes)
time_end <- Sys.time()
# Evaluamos
fitness <- evaluate_individual(pop[1,], list_matrix_con, ground_clusters, num_clusters)
results <- list(individual = pop[1,], fitness = fitness)
dir.create(as.character(select))
# Guardamos los resultados
#file <- paste(seed,"results-rand.RData", sep="-")
file <- paste(1,"results-rand.RData", sep="-")
file <- paste(select,"/",file, sep="")
save(results, time_beginning, time_end, file=file)
}
seed <- 1
lapply(1:64, function (s) { random_search(data, metadata, s, s) })
rm(list=ls())
library(clValid)
# Cargamos el código del algoritmo
source("ssga.r")
# Cargamos los datos
raw_metadata <- read.table("meta.txt",sep="\t")
raw_data <- read.table("data.txt",sep="\t")
select_list <- 1:64
val_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
optimal_clus <- function(list_ch) {
set.seed(1)
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal", maxitems=1000)
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
select <- 1
seed <- 1
raw_data_t <- raw_data[which(raw_data$file_name %in% raw_metadata$file_name[select]),]
raw_metadata_t <- raw_metadata[select,]
list_matrix_con <- data_2_lmat(raw_data_t,raw_metadata_t)
num_genes <- ncol(list_matrix_con[[1]])
pop_size <- 10
prob_mutation <- 1 / num_genes
prob_crossover <- 0.8
max_eval <- 1000
max_eval <- 50
num_clusters <- optimal_clus(list_matrix_con)
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
set.seed(seed)
results <- ga_cluster_similarity(num_genes, pop_size, prob_mutation, prob_crossover, max_eval, list_matrix_con, ground_clusters, num_clusters)
results$num_clusters
results$median_gen
rm(list=ls())
library(clValid)
# Cargamos el código del algoritmo
source("ssga.r")
#######################################################################################
# Definimos una función auxiliar que retorna la moda estadística
val_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
optimal_clus <- function(list_ch) {
set.seed(1)
n_clust <- c(2:10)
ivs <- lapply(list_ch, function(lt) {
clValid(lt, n_clust, clMethods=c("kmeans"), validation="internal", maxitems=1000)
})
sel_measures <- c("Connectivity", "Dunn", "Silhouette")
oss <- lapply(ivs, function(iv) { optimalScores(iv, measures = sel_measures) })
num_clusters <- lapply(oss, function(os) { as.numeric(as.character(val_mode(os$Clusters))) })
return(num_clusters)
}
#######################################################################################
random_search <- function(raw_data, raw_metadata, select, seed) {
raw_data_t <- raw_data[which(raw_data$file_name %in% raw_metadata$file_name[select]),]
raw_metadata_t <- raw_metadata[select,]
# Convertimos los datos al formato de entrada del algoritmo
list_matrix_con <- data_2_lmat(raw_data_t,raw_metadata_t)
# Número de clusters
num_clusters <- optimal_clus(list_matrix_con)
# obtenemos la "verdad"
set.seed(1)
ground_clusters <- get_clusters( list_matrix_con, num_clusters )
# El número de genes corresponde a la cantidad de observaciones de un día
num_genes <- ncol(list_matrix_con[[1]])
# Generamos una serie de individuos aleatorios
time_beginning <- Sys.time()
set.seed(seed)
pop <- init_pop(1,num_genes)
time_end <- Sys.time()
# Evaluamos
fitness <- evaluate_individual(pop[1,], list_matrix_con, ground_clusters, num_clusters)
results <- list(individual = pop[1,], fitness = fitness, num_clusters = num_clusters)
dir.create(as.character(select))
# Guardamos los resultados
#file <- paste(seed,"results-rand.RData", sep="-")
file <- paste(1,"results-rand.RData", sep="-")
file <- paste(select,"/",file, sep="")
save(results, time_beginning, time_end, file=file)
}
# Elegimos una semilla por defecto
seed <- 1
# Revisamos si se ha pasado una nueva semilla por línea de comandos
args <- commandArgs(trailingOnly = TRUE)
if (length(args)==1) {
seed <- as.integer(args[1])
}
# Cargamos los datos
metadata <- read.table("meta.txt",sep="\t")
data <- read.table("data.txt",sep="\t")
#lapply(2:30, function (s) { random_search(data, metadata, 16, s) })
lapply(1:64, function (s) { random_search(data, metadata, s, s) })
rm(list=ls())
